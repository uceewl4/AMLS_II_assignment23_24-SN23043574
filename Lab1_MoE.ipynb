{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Mixtures of Experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how mixtures of experts can be used to boost performance.\n",
    "\n",
    "The objective of this lab is to classify images from Cifar10 (https://www.cs.toronto.edu/~kriz/cifar.html) to one of ten classes: {0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cifar10](cifar10_resize.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, a gating function is trained to pass examples to two experts which are trained separatly, where one expert is trained to classify images within the \"natural image\" category (e.g. cat, dog, etc) and another to classify images within the  \"artificial image\" category (e.g. plane, car). The experts are then used to boost the performance of a baseline architecture that classifies image to one of the 10 classes.\n",
    "\n",
    "Specifically, the mixture is built in the following order:\n",
    "1. A single model is trained to to classify all 10 classes. (This is included in the mixture, and is also our evaluation benchmark)\n",
    "\n",
    "2. An expert gating function is trained to recognise whether an image is of an artificial or  natural subject.\n",
    "\n",
    "3. An artificial expert is trained to classify artificial objects that have a label in {0, 1, 8, 9}.\n",
    "\n",
    "4. A natural expert is trained to classify natural objects that have a label in  {2, 3, 4, 5, 6, 7}.\n",
    "\n",
    "5. A gating function is trained to determine the contribution of the experts and the contribution of the baseline architecture to the final output.\n",
    "\n",
    "6. The mixture is built as illustrated in the figure below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](moe_architecture_illus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import concatenate, Lambda, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import pydot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (not to be changed)\n",
    "orig_classes = 10 ; gate0_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Parameters\n",
    "\n",
    "You can try changing the mixture parameters in the following piece of code, when doing so, consider the following:\n",
    "\n",
    "1 - Increasing the number of epochs increases the fit to training data, at some point this should cause over-fitting. Conversly, setting it low should cause under-fitting.\n",
    "\n",
    "2 - Increasing the number of training examples increases the number of learnable features.\n",
    "\n",
    "3 - Using a large model for different classifiers increases their capacity to learn. This increases the amount of required epochs for training, and also increases the risk of over-fitting.  只是模型的网络框架不一样\n",
    "\n",
    "By changing the parameters, the performance of the mixture of experts and the baseline classifier should change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training/testing examples per batch\n",
    "batch_size = 50\n",
    "\n",
    "# Training epochs. A higher number of epochs corresponds to \"more fitting to training data\"\n",
    "epochs = 10\n",
    "\n",
    "# Number of training/testing examples to use\n",
    "train_examples = 5000 # Max is 50000\n",
    "test_examples = 1000   # Max is 5000\n",
    "\n",
    "# Large/small model flags. Set to true to change a classifier to \"large\"\n",
    "use_large_experts = True\n",
    "use_large_gating_mlp = True\n",
    "use_large_baseline_classifier = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete previous model checkpoints\n",
    "# https://blog.csdn.net/ZauberC/article/details/125391367\n",
    "# 递归删除文件夹下所有的文件\n",
    "import shutil\n",
    "shutil.rmtree('gate0Cifar10', ignore_errors=True)\n",
    "shutil.rmtree('moe3Cifar10', ignore_errors=True)\n",
    "shutil.rmtree('natureCifar10', ignore_errors=True)\n",
    "shutil.rmtree('baseCifar10', ignore_errors=True)\n",
    "shutil.rmtree('artCifar10', ignore_errors=True)\n",
    "\n",
    "# get the newest model file within a directory\n",
    "def getNewestModel(model, dirname):\n",
    "    from glob import glob\n",
    "    target = os.path.join(dirname, '*')\n",
    "    files = [(f, os.path.getmtime(f)) for f in glob(target)]\n",
    "    print(files)\n",
    "    if len(files) == 0:\n",
    "        return model\n",
    "    else:\n",
    "        newestModel = sorted(files, key=lambda files: files[1])[-1]  # the last(newest) model\n",
    "        # https://www.python100.com/html/111929.html\n",
    "        # 按照模型的最后修改时间排序\n",
    "        model.load_weights(newestModel[0])  # 加载训练好的模型参数，load_weight到模型的文件名称\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3)\n",
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [5]\n",
      " [4]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "# load dataset  ; X: input images,  Y: class label ground truth\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train[:train_examples] ; x_test = x_test[:test_examples]\n",
    "y_train = y_train[:train_examples] ; y_test = y_test[:test_examples]\n",
    "print(x_train.shape)\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare x dataset\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255  # normalization\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train0:(5000, 10)\n",
      "y test0:(1000, 10)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train0 = keras.utils.to_categorical(y_train, orig_classes)\n",
    "y_test0 = keras.utils.to_categorical(y_test, orig_classes)\n",
    "\n",
    "print(\"y train0:{0}\\ny test0:{1}\".format(y_train0.shape, y_test0.shape))\n",
    "print(y_train0)\n",
    "# change into one-hot vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "cifarInput = Input(shape=(x_train.shape[1:]), name=\"input\")\n",
    "# 32x32x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small VGG-like model\n",
    "def simpleVGG(cifarInput, num_classes, name=\"vgg\"):\n",
    "    name = [name+str(i) for i in range(12)]\n",
    "    \n",
    "    # convolution and max pooling layers\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[0])(cifarInput)\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[1])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[2])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[3])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[4])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[5])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[6])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[7])(vgg)\n",
    "\n",
    "    # classification layers\n",
    "    vgg = Flatten(name=name[8])(vgg)\n",
    "    vgg = Dense(512, activation='relu', name=name[9])(vgg)\n",
    "    vgg = Dropout(0.5, name=name[10])(vgg)\n",
    "    vgg = Dense(num_classes, activation='softmax', name=name[11])(vgg)  # softmax probabilities output\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large VGG-like model\n",
    "def fatVGG(cifarInput, num_classes, name=\"vgg\"):\n",
    "    name = [name+str(i) for i in range(17)]\n",
    "    \n",
    "    # convolution and max pooling layers\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[0])(cifarInput)\n",
    "    vgg = Conv2D(32, (3, 3), padding='same', activation='relu', name=name[1])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[2])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[3])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[4])(vgg)\n",
    "    vgg = Conv2D(64, (3, 3), padding='same', activation='relu', name=name[5])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[6])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[7])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[8])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[9])(vgg)\n",
    "    vgg = Conv2D(128, (3, 3), padding='same', activation='relu', name=name[10])(vgg)\n",
    "    vgg = MaxPooling2D(pool_size=(2,2), name=name[11])(vgg)\n",
    "    vgg = Dropout(0.25, name=name[12])(vgg)\n",
    "\n",
    "    # classification layers\n",
    "    vgg = Flatten(name=name[13])(vgg)\n",
    "    vgg = Dense(512, activation='relu', name=name[14])(vgg)\n",
    "    vgg = Dropout(0.5, name=name[15])(vgg)\n",
    "    vgg = Dense(num_classes, activation='softmax', name=name[16])(vgg)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first gating network, to decide artificial or natural object\n",
    "if use_large_gating_mlp:\n",
    "    gate0VGG = fatVGG(cifarInput, gate0_classes, \"gate0\")  # binary classification\n",
    "else:\n",
    "    gate0VGG = simpleVGG(cifarInput, gate0_classes, \"gate0\")\n",
    "gate0Model = Model(cifarInput, gate0VGG)  # 为了方便之后拼接更多的层，可以把这个整体看成一个可增模型结构\n",
    "\n",
    "# base VGG  # 10 class classification\n",
    "if use_large_baseline_classifier:\n",
    "    baseVGG = fatVGG(cifarInput, orig_classes, \"base\")\n",
    "else:\n",
    "    baseVGG = simpleVGG(cifarInput, orig_classes, \"base\") \n",
    "baseModel = Model(cifarInput, baseVGG)\n",
    "\n",
    "# artificial expert VGG\n",
    "if use_large_experts:\n",
    "    artificialVGG = fatVGG(cifarInput, orig_classes, \"artificial\")\n",
    "else:\n",
    "    artificialVGG = simpleVGG(cifarInput, orig_classes, \"artificial\")\n",
    "artificialModel = Model(cifarInput, artificialVGG)\n",
    "\n",
    "# naturalVGG = fatVGG(cifarInput, orig_classes, \"natural\")\n",
    "if use_large_experts:\n",
    "    naturalVGG = fatVGG(cifarInput, orig_classes, \"natural\")\n",
    "else:\n",
    "    naturalVGG = simpleVGG(cifarInput, orig_classes, \"natural\")\n",
    "\n",
    "naturalModel = Model(cifarInput, naturalVGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 10-Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "baseModel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'posixpath' (frozen)>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# make saving directory for checkpoints\n",
    "baseSaveDir = \"./baseCifar10/\"\n",
    "print(os.path)\n",
    "if not os.path.isdir(baseSaveDir):\n",
    "    os.makedirs(baseSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "# https://blog.csdn.net/u014568072/article/details/110818232 earlystopping\n",
    "chkpt = os.path.join(baseSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "# 以指定的时间间隔保存最新的模型\n",
    "# https://blog.csdn.net/Marryvivien/article/details/126954192\n",
    "\n",
    "# load the newest model data from the directory if exists\n",
    "baseModel = getNewestModel(baseModel, baseSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2935 - accuracy: 0.1142\n",
      "Epoch 1: val_loss improved from inf to 2.26607, saving model to ./baseCifar10/Cifar10_.01-2.27.hdf5\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 2.2935 - accuracy: 0.1142 - val_loss: 2.2661 - val_accuracy: 0.1220\n",
      "Epoch 2/10\n",
      "  1/100 [..............................] - ETA: 13s - loss: 2.2669 - accuracy: 0.1200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anlly/anaconda3/envs/lab/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 2.1869 - accuracy: 0.1928\n",
      "Epoch 2: val_loss improved from 2.26607 to 2.00343, saving model to ./baseCifar10/Cifar10_.02-2.00.hdf5\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 2.1869 - accuracy: 0.1928 - val_loss: 2.0034 - val_accuracy: 0.2510\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9395 - accuracy: 0.2750\n",
      "Epoch 3: val_loss improved from 2.00343 to 1.83074, saving model to ./baseCifar10/Cifar10_.03-1.83.hdf5\n",
      "100/100 [==============================] - 19s 193ms/step - loss: 1.9395 - accuracy: 0.2750 - val_loss: 1.8307 - val_accuracy: 0.3260\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7955 - accuracy: 0.3226\n",
      "Epoch 4: val_loss improved from 1.83074 to 1.71004, saving model to ./baseCifar10/Cifar10_.04-1.71.hdf5\n",
      "100/100 [==============================] - 19s 190ms/step - loss: 1.7955 - accuracy: 0.3226 - val_loss: 1.7100 - val_accuracy: 0.3640\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7266 - accuracy: 0.3552\n",
      "Epoch 5: val_loss improved from 1.71004 to 1.66845, saving model to ./baseCifar10/Cifar10_.05-1.67.hdf5\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 1.7266 - accuracy: 0.3552 - val_loss: 1.6684 - val_accuracy: 0.3900\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6379 - accuracy: 0.3886\n",
      "Epoch 6: val_loss improved from 1.66845 to 1.57667, saving model to ./baseCifar10/Cifar10_.06-1.58.hdf5\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 1.6379 - accuracy: 0.3886 - val_loss: 1.5767 - val_accuracy: 0.4260\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 0.4070\n",
      "Epoch 7: val_loss improved from 1.57667 to 1.51248, saving model to ./baseCifar10/Cifar10_.07-1.51.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 1.5871 - accuracy: 0.4070 - val_loss: 1.5125 - val_accuracy: 0.4620\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5123 - accuracy: 0.4418\n",
      "Epoch 8: val_loss improved from 1.51248 to 1.47196, saving model to ./baseCifar10/Cifar10_.08-1.47.hdf5\n",
      "100/100 [==============================] - 19s 190ms/step - loss: 1.5123 - accuracy: 0.4418 - val_loss: 1.4720 - val_accuracy: 0.4690\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4486 - accuracy: 0.4694\n",
      "Epoch 9: val_loss improved from 1.47196 to 1.45888, saving model to ./baseCifar10/Cifar10_.09-1.46.hdf5\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.4486 - accuracy: 0.4694 - val_loss: 1.4589 - val_accuracy: 0.4820\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4009 - accuracy: 0.4782\n",
      "Epoch 10: val_loss improved from 1.45888 to 1.37151, saving model to ./baseCifar10/Cifar10_.10-1.37.hdf5\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 1.4009 - accuracy: 0.4782 - val_loss: 1.3715 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x283f07cd0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "baseModel.fit(x_train, y_train0,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_test0),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./baseCifar10/Cifar10_.10-1.37.hdf5', 1706385937.771537), ('./baseCifar10/Cifar10_.08-1.47.hdf5', 1706385894.5169065), ('./baseCifar10/Cifar10_.05-1.67.hdf5', 1706385838.254511), ('./baseCifar10/Cifar10_.06-1.58.hdf5', 1706385857.0048165), ('./baseCifar10/Cifar10_.09-1.46.hdf5', 1706385918.046521), ('./baseCifar10/Cifar10_.02-2.00.hdf5', 1706385781.0059214), ('./baseCifar10/Cifar10_.04-1.71.hdf5', 1706385819.2838368), ('./baseCifar10/Cifar10_.03-1.83.hdf5', 1706385800.3182273), ('./baseCifar10/Cifar10_.07-1.51.hdf5', 1706385875.6231842), ('./baseCifar10/Cifar10_.01-2.27.hdf5', 1706385759.8907313)]\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 1.3715 - accuracy: 0.5000\n",
      "[1.3715049028396606, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# evaluate: testing\n",
    "baseModel = getNewestModel(baseModel, baseSaveDir)  # 先load训练好的model然后再testing\n",
    "baseScore = baseModel.evaluate(x_test, y_test0)\n",
    "print(baseScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train 2-Class Natural/Artificial Classifier\n",
    "\n",
    "The expert gating model determines whether an image is \"natural\" or \"artificial\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y trainG0:(5000, 2)\n",
      "y testG0:(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Make ground truth for whether an example is \"natural\" or \"artificial\"\n",
    "y_trainG0 = np.array([0 if i in [0,1,8,9] else 1 for i in y_train])\n",
    "y_testG0 = np.array([0 if i in [0,1,8,9] else 1 for i in y_test])\n",
    "\n",
    "y_trainG0 = keras.utils.to_categorical(y_trainG0, 2)\n",
    "y_testG0  = keras.utils.to_categorical(y_testG0, 2)\n",
    "\n",
    "print(\"y trainG0:{0}\\ny testG0:{1}\".format(y_trainG0.shape, y_testG0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "gate0Model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# make saving directory for check point\n",
    "gate0SaveDir = \"./gate0Cifar10/\"\n",
    "if not os.path.isdir(gate0SaveDir):\n",
    "    os.makedirs(gate0SaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(gate0SaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data from the directory if exists\n",
    "gate0Model = getNewestModel(gate0Model, gate0SaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.7392\n",
      "Epoch 1: val_loss improved from inf to 0.39944, saving model to ./gate0Cifar10/Cifar10_.01-0.40.hdf5\n",
      "100/100 [==============================] - 21s 200ms/step - loss: 0.5145 - accuracy: 0.7392 - val_loss: 0.3994 - val_accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8632\n",
      "Epoch 2: val_loss improved from 0.39944 to 0.35131, saving model to ./gate0Cifar10/Cifar10_.02-0.35.hdf5\n",
      "100/100 [==============================] - 19s 196ms/step - loss: 0.3365 - accuracy: 0.8632 - val_loss: 0.3513 - val_accuracy: 0.8570\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.8758\n",
      "Epoch 3: val_loss improved from 0.35131 to 0.28798, saving model to ./gate0Cifar10/Cifar10_.03-0.29.hdf5\n",
      "100/100 [==============================] - 20s 205ms/step - loss: 0.2985 - accuracy: 0.8758 - val_loss: 0.2880 - val_accuracy: 0.8790\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.8840\n",
      "Epoch 4: val_loss did not improve from 0.28798\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 0.2742 - accuracy: 0.8840 - val_loss: 0.2911 - val_accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.8906\n",
      "Epoch 5: val_loss improved from 0.28798 to 0.27235, saving model to ./gate0Cifar10/Cifar10_.05-0.27.hdf5\n",
      "100/100 [==============================] - 20s 197ms/step - loss: 0.2644 - accuracy: 0.8906 - val_loss: 0.2723 - val_accuracy: 0.8850\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9008\n",
      "Epoch 6: val_loss improved from 0.27235 to 0.26318, saving model to ./gate0Cifar10/Cifar10_.06-0.26.hdf5\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.2492 - accuracy: 0.9008 - val_loss: 0.2632 - val_accuracy: 0.8910\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.9004\n",
      "Epoch 7: val_loss improved from 0.26318 to 0.23022, saving model to ./gate0Cifar10/Cifar10_.07-0.23.hdf5\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.2422 - accuracy: 0.9004 - val_loss: 0.2302 - val_accuracy: 0.9120\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9084\n",
      "Epoch 8: val_loss did not improve from 0.23022\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.2262 - accuracy: 0.9084 - val_loss: 0.2423 - val_accuracy: 0.9070\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9080\n",
      "Epoch 9: val_loss did not improve from 0.23022\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.2270 - accuracy: 0.9080 - val_loss: 0.2433 - val_accuracy: 0.9040\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14bfbd990>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "gate0Model.fit(x_train, y_trainG0,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_test, y_testG0),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./gate0Cifar10/Cifar10_.05-0.27.hdf5', 1706386040.6111171), ('./gate0Cifar10/Cifar10_.07-0.23.hdf5', 1706386078.2443082), ('./gate0Cifar10/Cifar10_.01-0.40.hdf5', 1706385960.2594962), ('./gate0Cifar10/Cifar10_.03-0.29.hdf5', 1706386000.1423075), ('./gate0Cifar10/Cifar10_.02-0.35.hdf5', 1706385979.7541835), ('./gate0Cifar10/Cifar10_.06-0.26.hdf5', 1706386059.6627994)]\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 0.2302 - accuracy: 0.9120\n",
      "[0.23021505773067474, 0.9120000004768372]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "gate0Model = getNewestModel(gate0Model, gate0SaveDir)\n",
    "gate0Score = gate0Model.evaluate(x_test, y_testG0)\n",
    "print(gate0Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train \"Natural\" and \"Artificial\" Experts\n",
    "<br>\n",
    "The expert networks are specialized in predicting a certain classes.<br>\n",
    "Each network is only trained with its specialized field: the artificial expert get trained for labels 0, 1, 8 and 9; the natural expert for labels 2, 3, 4, 5, 6 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the position of artificial images and natural images in training and test dataset\n",
    "artTrain = [i for i in range(len(y_train)) if y_train[i] in [0,1,8,9]]\n",
    "natureTrain = [i for i in range(len(y_train)) if y_train[i] in [2,3,4,5,6,7]]\n",
    "artTest = [i for i in range(len(y_test)) if y_test[i] in [0,1,8,9]]\n",
    "natureTest = [i for i in range(len(y_test)) if y_test[i] in [2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get artificial dataset and natural dataset\n",
    "# separate out artificial and natural\n",
    "x_trainArt = x_train[artTrain]\n",
    "x_testArt = x_test[artTest]\n",
    "y_trainArt = y_train[artTrain]\n",
    "y_testArt = y_test[artTest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial expert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train art:(1983, 10)\n",
      "y test art:(407, 10)\n"
     ]
    }
   ],
   "source": [
    "# for artificial dataset\n",
    "y_trainArt = keras.utils.to_categorical(y_trainArt, orig_classes)\n",
    "y_testArt = keras.utils.to_categorical(y_testArt, orig_classes)\n",
    "\n",
    "print(\"y train art:{0}\\ny test art:{1}\".format(y_trainArt.shape, y_testArt.shape))\n",
    "\n",
    "# why still use 10 classes for one-hot vector here? can we reduce it to 6-class and 4-class, or we just want\n",
    "# to keep the compatibility for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "artificialModel.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=Adam(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# make saving directory for check point\n",
    "artSaveDir = \"./artCifar10/\"\n",
    "if not os.path.isdir(artSaveDir):\n",
    "    os.makedirs(artSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(artSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "artificialModel = getNewestModel(artificialModel, artSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.2491\n",
      "Epoch 1: val_loss improved from inf to 1.39926, saving model to ./artCifar10/Cifar10_.01-1.40.hdf5\n",
      "40/40 [==============================] - 8s 194ms/step - loss: 1.5449 - accuracy: 0.2491 - val_loss: 1.3993 - val_accuracy: 0.2678\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.3876 - accuracy: 0.3026\n",
      "Epoch 2: val_loss improved from 1.39926 to 1.30413, saving model to ./artCifar10/Cifar10_.02-1.30.hdf5\n",
      "40/40 [==============================] - 8s 194ms/step - loss: 1.3876 - accuracy: 0.3026 - val_loss: 1.3041 - val_accuracy: 0.4693\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.2166 - accuracy: 0.4473\n",
      "Epoch 3: val_loss improved from 1.30413 to 1.13554, saving model to ./artCifar10/Cifar10_.03-1.14.hdf5\n",
      "40/40 [==============================] - 8s 209ms/step - loss: 1.2166 - accuracy: 0.4473 - val_loss: 1.1355 - val_accuracy: 0.5233\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.0891 - accuracy: 0.5078\n",
      "Epoch 4: val_loss improved from 1.13554 to 1.06485, saving model to ./artCifar10/Cifar10_.04-1.06.hdf5\n",
      "40/40 [==============================] - 8s 197ms/step - loss: 1.0891 - accuracy: 0.5078 - val_loss: 1.0648 - val_accuracy: 0.5111\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.0426 - accuracy: 0.5325\n",
      "Epoch 5: val_loss improved from 1.06485 to 1.02846, saving model to ./artCifar10/Cifar10_.05-1.03.hdf5\n",
      "40/40 [==============================] - 8s 191ms/step - loss: 1.0426 - accuracy: 0.5325 - val_loss: 1.0285 - val_accuracy: 0.5504\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.0130 - accuracy: 0.5441\n",
      "Epoch 6: val_loss did not improve from 1.02846\n",
      "40/40 [==============================] - 8s 195ms/step - loss: 1.0130 - accuracy: 0.5441 - val_loss: 1.0661 - val_accuracy: 0.5037\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.9454 - accuracy: 0.5870\n",
      "Epoch 7: val_loss improved from 1.02846 to 0.94017, saving model to ./artCifar10/Cifar10_.07-0.94.hdf5\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 0.9454 - accuracy: 0.5870 - val_loss: 0.9402 - val_accuracy: 0.5897\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.6172\n",
      "Epoch 8: val_loss improved from 0.94017 to 0.92437, saving model to ./artCifar10/Cifar10_.08-0.92.hdf5\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 0.8737 - accuracy: 0.6172 - val_loss: 0.9244 - val_accuracy: 0.6020\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8595 - accuracy: 0.6359\n",
      "Epoch 9: val_loss improved from 0.92437 to 0.86936, saving model to ./artCifar10/Cifar10_.09-0.87.hdf5\n",
      "40/40 [==============================] - 8s 190ms/step - loss: 0.8595 - accuracy: 0.6359 - val_loss: 0.8694 - val_accuracy: 0.6339\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.6606\n",
      "Epoch 10: val_loss did not improve from 0.86936\n",
      "40/40 [==============================] - 8s 193ms/step - loss: 0.8011 - accuracy: 0.6606 - val_loss: 0.9084 - val_accuracy: 0.6437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2836b6310>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "artificialModel.fit(x_trainArt, y_trainArt,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_testArt, y_testArt),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./artCifar10/Cifar10_.08-0.92.hdf5', 1706386180.8181164), ('./artCifar10/Cifar10_.02-1.30.hdf5', 1706386133.4525778), ('./artCifar10/Cifar10_.04-1.06.hdf5', 1706386149.4936426), ('./artCifar10/Cifar10_.03-1.14.hdf5', 1706386141.6884685), ('./artCifar10/Cifar10_.05-1.03.hdf5', 1706386157.0556881), ('./artCifar10/Cifar10_.09-0.87.hdf5', 1706386188.3284364), ('./artCifar10/Cifar10_.07-0.94.hdf5', 1706386172.8703427), ('./artCifar10/Cifar10_.01-1.40.hdf5', 1706386125.765381)]\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.8694 - accuracy: 0.6339\n",
      "[0.8693640232086182, 0.6339066624641418]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "artificialModel = getNewestModel(artificialModel, artSaveDir)\n",
    "artScore = artificialModel.evaluate(x_testArt, y_testArt)\n",
    "print(artScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Natural expert network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for natural dataset\n",
    "x_trainNat = x_train[natureTrain]\n",
    "x_testNat = x_test[natureTest]\n",
    "y_trainNat = y_train[natureTrain]\n",
    "y_testNat = y_test[natureTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train nature:(3017, 10)\n",
      "y test nature:(593, 10)\n"
     ]
    }
   ],
   "source": [
    "# get natural dataset\n",
    "y_trainNat = keras.utils.to_categorical(y_trainNat, orig_classes)\n",
    "y_testNat = keras.utils.to_categorical(y_testNat, orig_classes)\n",
    "\n",
    "print(\"y train nature:{0}\\ny test nature:{1}\".format(y_trainNat.shape, y_testNat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "naturalModel.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=Adam(),\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# make saving directory for check point\n",
    "natSaveDir = \"./natureCifar10/\"\n",
    "if not os.path.isdir(natSaveDir):\n",
    "    os.makedirs(natSaveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(natSaveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "naturalModel = getNewestModel(naturalModel, natSaveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - ETA: 0s - loss: 1.8982 - accuracy: 0.1644\n",
      "Epoch 1: val_loss improved from inf to 1.81940, saving model to ./natureCifar10/Cifar10_.01-1.82.hdf5\n",
      "61/61 [==============================] - 13s 194ms/step - loss: 1.8982 - accuracy: 0.1644 - val_loss: 1.8194 - val_accuracy: 0.1518\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.8141 - accuracy: 0.1840\n",
      "Epoch 2: val_loss improved from 1.81940 to 1.81219, saving model to ./natureCifar10/Cifar10_.02-1.81.hdf5\n",
      "61/61 [==============================] - 12s 202ms/step - loss: 1.8141 - accuracy: 0.1840 - val_loss: 1.8122 - val_accuracy: 0.1602\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7776 - accuracy: 0.2340\n",
      "Epoch 3: val_loss improved from 1.81219 to 1.69517, saving model to ./natureCifar10/Cifar10_.03-1.70.hdf5\n",
      "61/61 [==============================] - 12s 194ms/step - loss: 1.7776 - accuracy: 0.2340 - val_loss: 1.6952 - val_accuracy: 0.2698\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.7064 - accuracy: 0.2761\n",
      "Epoch 4: val_loss improved from 1.69517 to 1.63483, saving model to ./natureCifar10/Cifar10_.04-1.63.hdf5\n",
      "61/61 [==============================] - 12s 200ms/step - loss: 1.7064 - accuracy: 0.2761 - val_loss: 1.6348 - val_accuracy: 0.3423\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.6247 - accuracy: 0.3225\n",
      "Epoch 5: val_loss improved from 1.63483 to 1.60018, saving model to ./natureCifar10/Cifar10_.05-1.60.hdf5\n",
      "61/61 [==============================] - 12s 195ms/step - loss: 1.6247 - accuracy: 0.3225 - val_loss: 1.6002 - val_accuracy: 0.3491\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.3497\n",
      "Epoch 6: val_loss improved from 1.60018 to 1.51311, saving model to ./natureCifar10/Cifar10_.06-1.51.hdf5\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 1.5695 - accuracy: 0.3497 - val_loss: 1.5131 - val_accuracy: 0.4098\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.5158 - accuracy: 0.3898\n",
      "Epoch 7: val_loss improved from 1.51311 to 1.49053, saving model to ./natureCifar10/Cifar10_.07-1.49.hdf5\n",
      "61/61 [==============================] - 13s 217ms/step - loss: 1.5158 - accuracy: 0.3898 - val_loss: 1.4905 - val_accuracy: 0.3980\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.4678 - accuracy: 0.4107\n",
      "Epoch 8: val_loss improved from 1.49053 to 1.47615, saving model to ./natureCifar10/Cifar10_.08-1.48.hdf5\n",
      "61/61 [==============================] - 12s 197ms/step - loss: 1.4678 - accuracy: 0.4107 - val_loss: 1.4762 - val_accuracy: 0.4250\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.3967 - accuracy: 0.4398\n",
      "Epoch 9: val_loss did not improve from 1.47615\n",
      "61/61 [==============================] - 12s 203ms/step - loss: 1.3967 - accuracy: 0.4398 - val_loss: 1.6571 - val_accuracy: 0.4013\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - ETA: 0s - loss: 1.3808 - accuracy: 0.4561\n",
      "Epoch 10: val_loss improved from 1.47615 to 1.36770, saving model to ./natureCifar10/Cifar10_.10-1.37.hdf5\n",
      "61/61 [==============================] - 13s 205ms/step - loss: 1.3808 - accuracy: 0.4561 - val_loss: 1.3677 - val_accuracy: 0.4587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14e148990>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "naturalModel.fit(x_trainNat, y_trainNat,\n",
    "               batch_size=batch_size,\n",
    "               epochs=epochs,\n",
    "               validation_data=(x_testNat, y_testNat),\n",
    "               callbacks=[es_cb,cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('./natureCifar10/Cifar10_.10-1.37.hdf5', 1706386319.2599046), ('./natureCifar10/Cifar10_.03-1.70.hdf5', 1706386233.3922484), ('./natureCifar10/Cifar10_.05-1.60.hdf5', 1706386257.321572), ('./natureCifar10/Cifar10_.07-1.49.hdf5', 1706386282.4135869), ('./natureCifar10/Cifar10_.08-1.48.hdf5', 1706386294.404692), ('./natureCifar10/Cifar10_.01-1.82.hdf5', 1706386209.376171), ('./natureCifar10/Cifar10_.02-1.81.hdf5', 1706386221.6177313), ('./natureCifar10/Cifar10_.04-1.63.hdf5', 1706386245.505035), ('./natureCifar10/Cifar10_.06-1.51.hdf5', 1706386269.277734)]\n",
      "19/19 [==============================] - 1s 43ms/step - loss: 1.3677 - accuracy: 0.4587\n",
      "[1.3676996231079102, 0.45868465304374695]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "naturalModel = getNewestModel(naturalModel, natSaveDir)\n",
    "natScore = naturalModel.evaluate(x_testNat, y_testNat)\n",
    "print(natScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the weights of all trained models so far (i.e. baseline, experts, and expert gating models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in baseModel.layers:\n",
    "    l.trainable = False\n",
    "for l in gate0Model.layers:\n",
    "    l.trainable = False\n",
    "for l in artificialModel.layers:\n",
    "    l.trainable = False\n",
    "for l in naturalModel.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Connecting the overall networks to form the mixture of experts model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-gate\n",
    "\n",
    "Up to this point, we have a baseline classifier which classifies the 10 classes, we have 2 experts which each classify the 10 classes but specialise in classifying either the natural or artificial categories of classes, and we have a first gate which decides which of the experts to choose for the given cifar input. We want our second gate to be able to take in the cifar input and decide what the importance should be of the output of the i) baseline and ii) chosen expert, thereby determining the importance of the baseline and the chosen expert in producing a final MoE output prediction. To do this, the second gate will be composed of 2 sub-gates; one for each expert.\n",
    "\n",
    "*Sub-gate Structure*: First layer of sub-gate is our (32, 32, 3) input layer as before which takes in the cifar data -> flatten input -> pass through 512 unit dense layer with relu activation function -> pass through dropout layer which randomly sets units to 0 with probability 0.5 -> pass through orig_classes x 2 = 10 x 2 = 20 unit dense layer with softmax activation function -> now have importance values for the i) baseline and ii) chosen expert -> reshape this 1D output into (10, 2) output. I.e. along [:, 0], have a (10,) tensor of what the sub-gate 'thinks' the importance is of the 10 baseline classifier outputs, and along [:,1], have a (10,) tensor of what the sub-gate 'thinks' the importance is of the expert.\n",
    "\n",
    "Instantiate one of these sub-gates for each expert. Whichever expert is chosen by the first binary classifier 'hard' gate will determine which corresponding expert sub-gate is used to 'soft gate' between the baseline and the chosen expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sub-Gate network, for the second gating network layer\n",
    "def subGate(cifarInput, orig_classes, name=\"subGate\"):\n",
    "    name = [name+str(i) for i in range(5)]\n",
    "    subgate = Flatten(name=name[0])(cifarInput)\n",
    "    subgate = Dense(512, activation='relu', name=name[1])(subgate)\n",
    "    subgate = Dropout(0.5, name=name[2])(subgate)\n",
    "    subgate = Dense(orig_classes*2, activation='softmax', name=name[3])(subgate)\n",
    "    subgate = Reshape((orig_classes, 2), name=name[4])(subgate)\n",
    "    return subgate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the artificial gating network\n",
    "artGate = subGate(cifarInput, orig_classes, \"artExpertGate\")\n",
    "\n",
    "# the natural gating network\n",
    "natureGate = subGate(cifarInput, orig_classes, \"natureExpertGate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-gate Lambda\n",
    "\n",
    "Want this layer to take outputs of i) baseline ii) expert and iii) sub-gate of the corresponding expert -> get logit outputs for each of the 10 orig_classes\n",
    "\n",
    "- Takes in argument gx, which is a list of 3 tensors (the output of i) baseline ii) expert iii) corresponding expert sub-gate)\n",
    "\n",
    "- gx[0] -> baseline output tensor (10,). Is a softmax output for each of the 10 classes\n",
    "\n",
    "- gx[1] -> expert network output tensor (10,). Is a softmax output for each of the 10 classes. Which expert's output reached here depends on the binary classifier output of the first gate (we will implement the logic of choosing the expert when we tie all the models together, see below).\n",
    "\n",
    "- gx[2] -> corresponding expert sub-gate output tensor (10,2,). \n",
    "- gx[2][:,:,0] -> baseline importance tensor of shape (10,). Is what the sub-gate thinks the importance is of each of the 10 baseline output classes. \n",
    "- gx[2][:,:,1] -> expert importance tensor of shape (10,). Is what the sub-gate thinks the importance is of each of the 10 expert output classes.\n",
    "\n",
    "We ultimately want a logit output for each of the 10 classes. We want this output to be determined by what the i) baseline and ii) expert thought, weighted by the importance of what the sub-gate thought. To do this inference, we can define a simple function which: i) multiplies the baseline's output by the sub-gate's baseline importance -> get a (10,) tensor ii) multiplies the expert's output by the sub-gate's expert importance -> get a (10,) tensor iii) sum these two importance-weighted terms to get a final (10,) tensor of logit outputs (one for each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inference calculation with Keras Lambda layer with base VGG, expert network and the second gating network of corresponding expert as input\n",
    "# the inference is calculated as sum of multiplications of base VGG inference output and its importance, and expert network inference output and its importance\n",
    "def subGateLambda(base, expert, subgate):\n",
    "    output = Lambda(lambda gx: (gx[0]*gx[2][:,:,0]) + (gx[1]*gx[2][:,:,1]), output_shape=(orig_classes,))([base, expert, subgate])\n",
    "    return output\n",
    "\n",
    "# DEBUG\n",
    "# def subGateLambda(base, expert, subgate):\n",
    "#     output = Lambda(lambda gx: print('\\ngx: {}\\ngx[0]: {}\\ngx[2][:,:,0]: {}\\ngx[1]: {}\\ngx[2][:,:,1]: {}'.format(gx, gx[0],gx[2][:,:,0],gx[1],gx[2][:,:,1])))([base, expert, subgate])\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting the Networks\n",
    "\n",
    "Now we just need to i) tie all of the above models together and ii) implement the logic for choosing an expert at the first gate. The first 'expert gate' binary classifier is a 'hard gate' since it will choose one expert and block the other. The second gate (a sub-gate) is a 'soft gate' since it will apply its importance weights across the i) baseline and ii) chosen expert.\n",
    "\n",
    "To do this, we can define a layer which takes the outputs of i) baseline ii) first gate iii) artificial expert iv) natural expert v) artificial sub-gate vi) natural sub-gate.\n",
    "\n",
    "- Takes in argument gx, which is a list of 6 tensors (the output of i) baseline ii) first gate iii) artificial expert iv) natural expert v) artificial sub-gate vi) natural sub-gate)\n",
    "- gx[0] -> baseline output tensor (10,)\n",
    "- gx[1] -> first gate binary output tensor (2,)\n",
    "- gx[2] -> artificial expert output tensor (10,)\n",
    "- gx[3] -> natural expert output tensor (10,)\n",
    "- gx[4] -> artificial sub-gate output tensor (10,2,)\n",
    "- gx[5] -> natural sub-gate output tensor (10,2,)\n",
    "\n",
    "We want to implement the logic that the first gate's chosen expert's output and corresponding sub-gate output should be passed (along with the baseline's output) to the sub-gate lambda function defined previously. To do this, we can use the Keras backend switch function, which will pass the chosen expert's output and its corresponding sub-gate output to the sub-gate lambda depending on which of the 2 outputs of the first gate was greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "# connecting the overall networks.\n",
    "# the Keras backend switch works as deciding with the first gating network, leading to artificial or natural gate\n",
    "# https://blog.csdn.net/wdh315172/article/details/105437494\n",
    "# lambda将任意表达式封装成一个层级对象\n",
    "# 所谓的一个gate就是一个fusion连结层\n",
    "output = Lambda(lambda gx: K.switch(tf.expand_dims(gx[1][:,0],axis=1) > tf.expand_dims(gx[1][:,1],axis=1), \n",
    "                                    subGateLambda(gx[0], gx[2], gx[4]), # choose the larger one\n",
    "                                    subGateLambda(gx[0], gx[3], gx[5])), \n",
    "                output_shape=(orig_classes,))([baseVGG, gate0VGG, artificialVGG, naturalVGG, artGate, natureGate])\n",
    "# gx[1] from gate0VGG of binary classification, 属于哪个类别就交给哪个expert去处理\n",
    "\n",
    "# https://gist.github.com/monk1337/22b00851302ccc8fddf84404e5dd00f8\n",
    "# DEBUG\n",
    "# output = Lambda(lambda gx: print('\\ngx: {}\\ngx[0]: {}\\ngx[1]: {}\\ngx[2]: {}\\ngx[3]: {}\\ngx[4]: {}\\ngx[5]: {}'.format(gx, gx[0], gx[1], gx[2], gx[3], gx[4], gx[5])), \n",
    "#                 output_shape=(orig_classes,))([baseVGG, gate0VGG, artificialVGG, naturalVGG, artGate, natureGate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the mixture of experts model\n",
    "model = Model(cifarInput, output)  # integrate into entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have already trained the baseline, the experts, and the first expert gate. Now we need only train the sub-gates and the final Lambda inference layer, which will take the outputs of the above trained models and learn to output a final (10,) MoE prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.input_layer.InputLayer object at 0x14c33bc90> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4fa2d0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x28ea7dbd0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4f5b50> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b43e450> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x29d5a2b10> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x283f04410> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x28e986050> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2ec2f25d0> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x29d9b7f50> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x28ea8b090> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x2c6f7f350> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x30f097ed0> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x30f4f5450> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x28eb28450> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x30f483490> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b4286d0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4f6f10> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2c73a4710> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b422090> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2efe99950> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2ec2f0710> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2efea9210> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4eef90> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2a1d93750> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x2ee034e50> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x28e989650> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x30f407a50> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x14b4373d0> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b4068d0> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14c30fe10> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x2ec1259d0> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b44bed0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4f52d0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2c73e7d50> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b42b110> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b456290> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x28e9b1590> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4ef790> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b42bc50> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2ec2f1450> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2c738f2d0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x30f4eda50> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b428f50> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x14b4579d0> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x30ebe47d0> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x30ebc9610> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x28d53a550> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x30f4e9490> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x2c73ce710> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x30f4eb690> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b416e50> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b45b050> False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x14e19b490> True\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x288292b50> True\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x30f030650> False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x30f075490> False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x2ec2e6290> False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x14b45acd0> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x14e1e9a50> True\n",
      "<keras.src.layers.core.dense.Dense object at 0x2882a7950> True\n",
      "<keras.src.layers.core.dense.Dense object at 0x30f4e9450> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x2efe5eb50> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x30f0e17d0> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x14b446310> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b44ab90> True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x288287590> True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x2efe8b550> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x30f42e410> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x290b03690> False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x14b43ff90> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x28822ac50> True\n",
      "<keras.src.layers.core.dense.Dense object at 0x14e03a310> True\n",
      "<keras.src.layers.core.dense.Dense object at 0x14b418210> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x30f4f7e90> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x14b437510> False\n",
      "<keras.src.layers.core.dense.Dense object at 0x28e9b1150> False\n",
      "<keras.src.layers.reshaping.reshape.Reshape object at 0x288277510> True\n",
      "<keras.src.layers.reshaping.reshape.Reshape object at 0x283657850> True\n",
      "<keras.src.layers.core.lambda_layer.Lambda object at 0x14e19b290> True\n"
     ]
    }
   ],
   "source": [
    "# show layers and if it's trainable or not\n",
    "# only the second gating network layers and the last Lambda inference layer are left trainable\n",
    "# because previous layers are all freezed after previous traning\n",
    "for l in model.layers:\n",
    "    print(l, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# make saving directory for check point\n",
    "saveDir = \"./moe3Cifar10/\"\n",
    "if not os.path.isdir(saveDir):\n",
    "    os.makedirs(saveDir)\n",
    "    \n",
    "# early stopping and model checkpoint\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "chkpt = os.path.join(saveDir, 'Cifar10_.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# load the newest model data if exists\n",
    "model = getNewestModel(model, saveDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 1.5375 - accuracy: 0.4972\n",
      "Epoch 1: val_loss improved from inf to 1.31862, saving model to ./moe3Cifar10/Cifar10_.01-1.32.hdf5\n",
      "100/100 [==============================] - 30s 286ms/step - loss: 1.5375 - accuracy: 0.4972 - val_loss: 1.3186 - val_accuracy: 0.5370\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.5622\n",
      "Epoch 2: val_loss improved from 1.31862 to 1.31822, saving model to ./moe3Cifar10/Cifar10_.02-1.32.hdf5\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.2418 - accuracy: 0.5622 - val_loss: 1.3182 - val_accuracy: 0.5420\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2312 - accuracy: 0.5636\n",
      "Epoch 3: val_loss improved from 1.31822 to 1.31666, saving model to ./moe3Cifar10/Cifar10_.03-1.32.hdf5\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.2312 - accuracy: 0.5636 - val_loss: 1.3167 - val_accuracy: 0.5380\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2295 - accuracy: 0.5744\n",
      "Epoch 4: val_loss did not improve from 1.31666\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.2295 - accuracy: 0.5744 - val_loss: 1.3175 - val_accuracy: 0.5430\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2326 - accuracy: 0.5672\n",
      "Epoch 5: val_loss improved from 1.31666 to 1.30542, saving model to ./moe3Cifar10/Cifar10_.05-1.31.hdf5\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.2326 - accuracy: 0.5672 - val_loss: 1.3054 - val_accuracy: 0.5460\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2350 - accuracy: 0.5680\n",
      "Epoch 6: val_loss did not improve from 1.30542\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 1.2350 - accuracy: 0.5680 - val_loss: 1.3075 - val_accuracy: 0.5450\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2250 - accuracy: 0.5694\n",
      "Epoch 7: val_loss improved from 1.30542 to 1.30418, saving model to ./moe3Cifar10/Cifar10_.07-1.30.hdf5\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 1.2250 - accuracy: 0.5694 - val_loss: 1.3042 - val_accuracy: 0.5470\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2245 - accuracy: 0.5764\n",
      "Epoch 8: val_loss improved from 1.30418 to 1.30375, saving model to ./moe3Cifar10/Cifar10_.08-1.30.hdf5\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.2245 - accuracy: 0.5764 - val_loss: 1.3037 - val_accuracy: 0.5490\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2256 - accuracy: 0.5748\n",
      "Epoch 9: val_loss improved from 1.30375 to 1.30218, saving model to ./moe3Cifar10/Cifar10_.09-1.30.hdf5\n",
      "100/100 [==============================] - 33s 337ms/step - loss: 1.2256 - accuracy: 0.5748 - val_loss: 1.3022 - val_accuracy: 0.5500\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2261 - accuracy: 0.5668\n",
      "Epoch 10: val_loss improved from 1.30218 to 1.30006, saving model to ./moe3Cifar10/Cifar10_.10-1.30.hdf5\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 1.2261 - accuracy: 0.5668 - val_loss: 1.3001 - val_accuracy: 0.5430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x282f0c510>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(x_train, y_train0,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test0),\n",
    "          callbacks=[es_cb, cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 170ms/step - loss: 1.3001 - accuracy: 0.5430\n",
      "[1.3000566959381104, 0.5429999828338623]\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "mixture_loss_accuracy = model.evaluate(x_test, y_test0)\n",
    "print(mixture_loss_accuracy)  # return loss and metrics\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that when final use the subgate lambda and the whole model, we use\n",
    "# the already trained model previously entirely, there is no need to train again and all weights are fixed,\n",
    "# but still input needed to be fed into the last gate, however, it goes through not only last gate but also previous all networks with \n",
    "# trained weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
